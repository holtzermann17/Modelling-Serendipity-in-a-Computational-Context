\section{Discussion} \label{sec:discussion}

  %% This is related to the notion of \emph{open discovery} which
  %% ``leads the creative knowledge discovery process from a given starting
  %%   domain towards a yet unknown second domain which at the end of
  %%   this process turns out to be connected with the first one.''

  %% However, Connections between these fields seems
  %% unexplored in practical work, though Ada Lovelace had already
  %% acknowledged the role of ``various collateral influences, besides
  %% the main and primary object attained'' \cite[p.~696]{lovelace} in
  %% all additions to knowledge.

% To merge:
%% Austin \cite[p.~78]{austin1978chase} advances two further
%% variations on Pasteur's famous principle, namely: \emph{Chance favours
%%   those in motion} (and generalisations such as ``curiosity about many
%% things, persistence, willingness to experiment and to explore''), and
%% \emph{chance favours the individualised action} (i.e., ``distinctive
%% hobbies, personal life styles, and activities peculiar to [the]
%% individual'').  These variants suggest that certain properties of the
%% investigator both introduce and constrain possibilities for chance
%% encounters and unexpected connections.

%% Our work in this paper does not report on system development, but we
%% nevertheless we have argued that serendipity is not strictly beyond
%% the reach of computational implementations.  Indeed, 


In Section \ref{sec:literature-summary}, we suggested that serendipity
is \emph{a form of creativity that happens in context, on the fly,
  with the active participation of a creative agent, but not entirely
  within that agent's control.}  %% The
%% perspective we developed is compatible with what
%% \citet{tonnessen2015uexkullian} calls ``Uexk\"ullian phenomenology.''
%% This conception of a world rich in interdependence across various
%% layers of mental processing is also compatible with Copeland's
%% The basic concern about AI is that given a long enough leash (or,
%% lead) and access to a suitable energy source, more sensors and
%% actuators, more processing power, and so on, computational systems
%% will run amok.  We might do well to compare Bostrom's reflections on
%% superintelligence \cite{bostrom2014superintelligence} with Ostrom's
%% reflections on the commons \cite{ostrom1999revisiting}.  Consider
%% that, from an ecological perspective, we are already grasping with
%% existential risks due to anthropogenic climate change.

Our account of serendipity can be contrasted with an earlier treatment due to Simonton.  
He suggested that `exceptional
creativity' is more likely to engage blind selection mechanisms, on
the view that ``blind variation generates the originality of an
idea'' \cite[p.~158]{simonton2010creative}.  He cites {\sf BACON} \cite{langley1987scientific} as an
example of a blind but nonetheless ``systematic'' search program,
based on ``heuristic methods in which a solution is no longer
guaranteed'' \cite[p.~169]{simonton2010creative}.  However, this
system, and the related example of a ``blind'' radar search
\cite[p.~383]{campbell1960blind} should be contrasted with Austin's
\emph{`barking up the right tree' phenomenon}: ``if you happen to be
the kind of person who hunts afield, it may be, in fact, your dog who
leads you up to the correct tree, and to a desirable conclusion''
\cite[p.~50]{austin1978chase}.
\citet[p.~720]{kockelman2011biosemiosis} contends that just as ``one
cannot offer an account of significance without an account of
selection'' also ``one cannot offer an account of selection without an
account of significance.''  In order to make good use of serendipity,
systems will need to model both the anticipation and appreciation of
valuable outcomes in an uncertain world.
If `blindness' came in degrees, we might expect to see the
propagation of prediction error through a broader system that works to
reduce surprise over the long term \cite{Kiverstein2017,Friston2012}.

Our six-phase model of serendipity examines necessary factors of serendipity
potential, but aside from requiring each facet of the model, we have
not had a lot to say about specific techniques or strategies for
encouraging serendipity.  \citet{bjorneborn2017three} expands upon
that theme in considerable detail.  He puts forward three major
``personal factors in serendipitous encounters'': \emph{curiosity},
\emph{mobility}, and \emph{sensitivity}.  These correspond to three
parallel environmental factors or affordances, which he calls
\emph{diversifiability}, \emph{traversability}, and
\emph{sensorability}.  Both sides of this balance are then described
in terms of sub-factors, with ten on each side.  While Bj\"orneborn
here traces an interesting parallel between agent and environment, he
does not comment explicitly on a parallel with the classic theory-of-mind-in-three-parts, namely ``\emph{conative},''
``\emph{cognitive},'' and ``\emph{affective}''
\cite{hilgard1980trilogy}.
%%
Thus for example \citet[p.~347]{boden1998creativity} comments that
creativity ``involves not only a cognitive dimension (the generation
of new ideas) but also motivation and emotion.''
%%
These dimensions may be active throughout the processes we've
described, which is why they did not fit cleanly into the alignment of
theories in Table \ref{tab:theory-summary}.

In a recent paper exploring serendipity in computer-generated fiction,
\citet{mccallum2018} reflect on how structured thinking about
serendipity can help designers of AI systems take advantage of the
``productive and perilous moment~[\ldots]~in which an unexpected event
or pattern occurs'' (p.~7).  The authors indicate their doubt as
whether computational art should be constrained to resemble human art.

The aesthetic question evokes a parallel question in the field of AI
ethics, where \citet{caliskan2017semantics} recommend ``the explicit
characterization of acceptable behavior'' and the ``explicit
instruction of rules of appropriate conduct.''  It seems unrealitic to
expect one set of fixed rules to apply universally in a world full of
``numerous and inter-complicated'' conditions \cite[p.~710]{lovelace}
and `circular-causal' loops \cite{loughran2018serendipity}.  An
approach to AI ethics that would fit better with the reasoning we have
outlined in this paper would require rules to be both explicit and
negotiable within meta-level institutions
\cite{corneli2016institutional}.  There is a practical consideration
which is that such institutions are can be structured by relatively
few principles, rather than an exhaustive set of rules, while
nevertheless being adaptable to a wide range of situations.

The institutional design problem recalls the model of design science
research, mentioned in Section \ref{sec:background}, which been
employed to scaffold various design tasks.  One recent example is a
methodology for component-based program synthesis that uses
type-theoretic descriptions to align components
\cite{10.1007/978-3-030-03427-6_35}.  \citet{pease2013discussion} had
outlined a related experiment that would introduce serendipity into
the construction of program flowcharts.  Technologies like type theory
and distributional semantics \cite{DBLP:journals/corr/abs-1803-09473}
could be used by future systems to both generate and interpret their
results.  This suggests the possibility of a new approach to
computational design and synthesis that engages in \emph{open
  discovery} as it moves ``from a given starting domain towards a yet
unknown second domain'' \cite{jurvsivc2012cross}.
% \cite{KWISTHOUT201784} - six different ways to lower prediction error

%% Insofar as human mental processing has evolved to elegantly handle inputs, kinematics, actions, and intentions \cite[p.~85]{KWISTHOUT201784} we could similarly be said to be designed for serendipity.  There is clearly quite a way before we have computational systems with comparable abilities.
